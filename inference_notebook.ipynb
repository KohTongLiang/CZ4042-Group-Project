{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "inference_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_uQcN2eMkrR5"
      ]
    },
    "interpreter": {
      "hash": "e068d1db7b46c849f789b3c4a85e9cf2c6ba07f44bbce4a761ed871e9e6f51a1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('MDP': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gP9hS6C6ova"
      },
      "source": [
        "# We explore this notebook and see how we can make modification to complete our tasks\n",
        "\n",
        "Some ideas\n",
        "\n",
        "\n",
        "*   Cross-gender identification\n",
        "* Age identification\n",
        "*   Deployment to mobile devices\n",
        "\n",
        "Dataset provided in assignment brief: https://susanqq.github.io/UTKFace/\n",
        "\n",
        "Download this: https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE?resourcekey=0-01Pth1hq20K4kuGVkp3oBw\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTdorWeQxdc7",
        "outputId": "df64e111-20ad-49f4-b78c-12a60ecb9c61"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3yl99hOe_F3"
      },
      "source": [
        "# **Age and Gender Estimation in TensorFlow ( Workbook 2, Gender Classification )**\n",
        "\n",
        "* For Age Estimation, go to [Workbook 1 ( Age Estimation )](https://colab.research.google.com/drive/1to2iolQGIVZgXFWRmRKZGrny5kfXk40h?usp=sharing)\n",
        "\n",
        "In this notebook, we train a Keras model to classify the gender of a person, given a *face-cropped* image. We use the famous [UTKFace Dataset](https://susanqq.github.io/UTKFace/), which contains 23K images where each image is labelled with its gender, age and ethinicity.\n",
        "\n",
        "\n",
        "> **Note: Please make sure that you are connected to the GPU runtime of Google Colab. Else, the training might take a decade long. Go to Runtime > Change runtime type > Hardware accelerator.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMlbjEzffKQP"
      },
      "source": [
        "## 1) **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb_CNn_ui6QT"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from tensorflow.keras.layers import *\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgOhn0cfrkg"
      },
      "source": [
        "## 2) **Processing the data**\n",
        "\n",
        "Once we've downloaded the dataset, we need to perform the following operations on the dataset, so that it can be used for training our model,\n",
        "\n",
        "* Reading the image files as 3D NumPy arrays. Note, we'll use 3-channeled RGB images for training the model, so each array will have a shape of `[ img_width , img_height , 3 ]`.\n",
        "\n",
        "* Split the filename so as to parse the gender of the person in corresponding image. We use the `tf.strings.split()` method for performing this task.\n",
        "\n",
        "* We one-hot encode the gender, as we'll perform *a two-class* classification.\n",
        "\n",
        "Once this operations have been performed, we are left with $N$ samples where each sample consists of image array `[ 128 , 128 , 3 ]` and its corresponding label ( one-hot encoded ), the gender of that person, which has a shape `[ 1 , 2 ]`\n",
        "\n",
        "We'll use `tf.data.Dataset` as it helps us to process the data faster, taking advantage of parallel computing. The above two operations will be mapped on each filename using `tf.data.Dataset.map` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqem4IKA2Nm6"
      },
      "source": [
        "# definitions for UTKDataset\n",
        "dataset_dict = {\n",
        "    'race_id': {\n",
        "        0: 'white', \n",
        "        1: 'black', \n",
        "        2: 'asian', \n",
        "        3: 'indian', \n",
        "        4: 'others'\n",
        "    },\n",
        "    'gender_id': {\n",
        "        0: 'male',\n",
        "        1: 'female'\n",
        "    }\n",
        "}\n",
        "\n",
        "dataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\n",
        "dataset_dict['race_alias'] = dict((r, i) for i, r in dataset_dict['race_id'].items())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m67XqZMHirhz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "fd4eda07-8c93-4092-f79f-cb7401d4b351"
      },
      "source": [
        "dir = '/content/drive/MyDrive/Dataset/UTK/UTKFace'\n",
        "\n",
        "# Image size for our model.\n",
        "# MODEL_INPUT_IMAGE_SIZE = [ 128 , 128 ]\n",
        "\n",
        "# TRAIN_TEST_SPLIT = 0.3\n",
        "\n",
        "# # Number of samples to take from dataset\n",
        "# NUM_SAMPLES = 20000\n",
        "\n",
        "# # Trick to one-hot encode the label.\n",
        "# y1 = tf.constant( [ 1. , 0. ] , dtype='float32' ) \n",
        "# y2 = tf.constant( [ 0. , 1. ] , dtype='float32' ) \n",
        "\n",
        "# # This method will be mapped for each filename in `list_ds`. \n",
        "# def parse_image(filename):\n",
        "#     # Read the image from the filename and resize it.\n",
        "#     image_raw = tf.io.read_file(filename)\n",
        "#     image = tf.image.decode_jpeg(image_raw ,channels=3) \n",
        "#     image = tf.image.resize(image ,MODEL_INPUT_IMAGE_SIZE) / 255\n",
        "\n",
        "#     # Split the filename to get the age and the gender. Convert the age ( str ) and the gender ( str ) to dtype float32.\n",
        "#     parts = tf.strings.split( tf.strings.split( filename , '/' )[ 2 ] , '_' )\n",
        "\n",
        "#     # One-hot encode the label\n",
        "#     gender = tf.strings.to_number(parts[1])\n",
        "#     gender = ( gender * y2 ) + ( ( 1 - gender ) * y1 )\n",
        "#     print(gender)\n",
        "\n",
        "#     return image, 2\n",
        "\n",
        "# # List all the image files in the given directory.\n",
        "# list_ds = tf.data.Dataset.list_files( f'{dir}/*' , shuffle=True )\n",
        "# # Map `parse_image` method to all filenames.\n",
        "# dataset = list_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
        "# # dataset = list_ds.map(lambda x: tf.py_function(func=parse_image, inp=[x], Tout=(tf.float32, tf.float32)),num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
        "# dataset = dataset.take( NUM_SAMPLES )\n",
        "# print(dataset)\n",
        "\n",
        "# for e in dataset:\n",
        "#     print(e)\n",
        "\n",
        "# Fraction of the dataset to be used for testing.\n",
        "split = 0.3\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "image_data = []\n",
        "\n",
        "def parse_data(filename):\n",
        "  try:\n",
        "    parts = filename.split('_')\n",
        "    age = parts[0]\n",
        "    gender = parts[1]\n",
        "    race = parts[2]\n",
        "    return int(age), dataset_dict['gender_id'][int(gender)], dataset_dict['race_id'][int(race)], filename\n",
        "  except Exception as e:\n",
        "    return None, None, None, None\n",
        "\n",
        "for i in os.listdir(dir):\n",
        "  age, gender, race, filename = parse_data(i)\n",
        "  if age is not None and gender is not None and race is not None and filename is not None:\n",
        "    image_data.append(parse_data(i))\n",
        "\n",
        "data = pd.DataFrame(image_data, columns=[\"age\", \"gender\", \"race\", \"filename\"])\n",
        "\n",
        "# 1-hot embedding\n",
        "# data['Age'] = tf.keras.utils.to_categorical(data['Age'])\n",
        "# data['Gender'] = tf.keras.utils.to_categorical(data['Gender'])\n",
        "# data['Racevalues'] = tf.keras.utils.to_categorical(data['Racevalues'])\n",
        "\n",
        "# train test split\n",
        "train, test = train_test_split(data, test_size = split)\n",
        "train.head(10)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>race</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20529</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>21_1_2_20170104021056028.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7211</th>\n",
              "      <td>35</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>35_0_0_20170117171138059.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19601</th>\n",
              "      <td>26</td>\n",
              "      <td>female</td>\n",
              "      <td>indian</td>\n",
              "      <td>26_1_3_20170104215700398.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14753</th>\n",
              "      <td>56</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>56_1_2_20170107213838566.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20085</th>\n",
              "      <td>23</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>23_0_0_20170104004006925.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20481</th>\n",
              "      <td>24</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>24_1_2_20170104020244348.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10652</th>\n",
              "      <td>28</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>28_1_2_20170116161415319.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10687</th>\n",
              "      <td>28</td>\n",
              "      <td>female</td>\n",
              "      <td>asian</td>\n",
              "      <td>28_1_2_20170116164552683.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3010</th>\n",
              "      <td>36</td>\n",
              "      <td>male</td>\n",
              "      <td>white</td>\n",
              "      <td>36_0_0_20170117184847906.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16275</th>\n",
              "      <td>15</td>\n",
              "      <td>female</td>\n",
              "      <td>white</td>\n",
              "      <td>15_1_0_20170109214633067.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  gender    race                               filename\n",
              "20529   21  female   asian  21_1_2_20170104021056028.jpg.chip.jpg\n",
              "7211    35    male   white  35_0_0_20170117171138059.jpg.chip.jpg\n",
              "19601   26  female  indian  26_1_3_20170104215700398.jpg.chip.jpg\n",
              "14753   56  female   asian  56_1_2_20170107213838566.jpg.chip.jpg\n",
              "20085   23    male   white  23_0_0_20170104004006925.jpg.chip.jpg\n",
              "20481   24  female   asian  24_1_2_20170104020244348.jpg.chip.jpg\n",
              "10652   28  female   asian  28_1_2_20170116161415319.jpg.chip.jpg\n",
              "10687   28  female   asian  28_1_2_20170116164552683.jpg.chip.jpg\n",
              "3010    36    male   white  36_0_0_20170117184847906.jpg.chip.jpg\n",
              "16275   15  female   white  15_1_0_20170109214633067.jpg.chip.jpg"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cn1WboV0kRn"
      },
      "source": [
        "def plot_distribution(pd_series):\n",
        "    labels = pd_series.value_counts().index.tolist()\n",
        "    counts = pd_series.value_counts().values.tolist()\n",
        "    \n",
        "    pie_plot = go.Pie(labels=labels, values=counts, hole=.3)\n",
        "    fig = go.Figure(data=[pie_plot])\n",
        "    fig.update_layout(title_text='Distribution for %s' % pd_series.name)\n",
        "    \n",
        "    fig.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkrViKmC0qdZ"
      },
      "source": [
        "plot_distribution(train['gender'])\n",
        "plot_distribution(train['race'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmQsWd2L1ZZy"
      },
      "source": [
        "fig = px.histogram(train, x=\"age\", nbins=20)\n",
        "fig.update_layout(title_text='Age distribution on Train Dataset')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96X2908p1gea"
      },
      "source": [
        "plot_distribution(test['gender'])\n",
        "plot_distribution(test['race'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxXeol_81glU"
      },
      "source": [
        "fig = px.histogram(test, x=\"age\", nbins=20)\n",
        "fig.update_layout(title_text='Age distribution on Test Dataset')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArDZcEaE3IPg"
      },
      "source": [
        "Face dataset generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkW34RPX2LAq"
      },
      "source": [
        "img_height = 128\n",
        "img_width = 128\n",
        "\n",
        "class FaceDataGenerator():\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = dataframe\n",
        "\n",
        "  def preprocess_image(self, file):\n",
        "    img = Image.open(file)\n",
        "    img = img.resize((img_width, img_height))\n",
        "    img = np.array(img) / 255.0\n",
        "    return img\n",
        "  \n",
        "  def alias(self):\n",
        "    self.dataframe['gender_id'] = self.dataframe['gender'].map(lambda gender: dataset_dict['gender_alias'][gender.strip()])\n",
        "    self.dataframe['race_id'] = self.dataframe['race'].map(lambda race: dataset_dict['race_alias'][race])\n",
        "    self.max_age = self.dataframe['age'].max()\n",
        "\n",
        "  def generate_images(self, is_training, batch_size=8):\n",
        "    # arrays to store our batched data\n",
        "    images, ages, races, genders = [], [], [], []\n",
        "    while True:\n",
        "      for idx in range(len(self.dataframe)):\n",
        "          person = self.dataframe.iloc[idx]\n",
        "          \n",
        "          age = person['age']\n",
        "          race = person['race_id']\n",
        "          gender = person['gender_id']\n",
        "          filename = person['filename']\n",
        "          \n",
        "          im = self.preprocess_image(dir + '/' + filename)\n",
        "          \n",
        "          ages.append(age / self.max_age)\n",
        "          races.append(to_categorical(race, len(dataset_dict['race_id'])))\n",
        "          genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\n",
        "          images.append(im)\n",
        "          \n",
        "          # yielding condition\n",
        "          if len(images) >= batch_size:\n",
        "              yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\n",
        "              images, ages, races, genders = [], [], [], []\n",
        "              \n",
        "      if not is_training:\n",
        "          break"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjxUvHFx30nG",
        "outputId": "c68126ab-f8c6-49f5-d6fd-470a9aa24d7b"
      },
      "source": [
        "train_gen = FaceDataGenerator(train)\n",
        "test_gen = FaceDataGenerator(test)\n",
        "train_gen.alias()\n",
        "test_gen.alias()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imXMA0cjxCNm"
      },
      "source": [
        "\n",
        "# testdatagenerator = ImageDataGenerator(rescale=1. /255)\n",
        "# testdata = testdatagenerator.flow_from_dataframe(dataframe=test,directory=dir,x_col=\"Filepath\",y_col=[\"Age\",\"Gender\",\"Racevalues\"],class_mode=\"multi_output\", batch_size=batch_size)\n",
        "\n",
        "# traindatagenerator = ImageDataGenerator(rescale=1. /255,shear_range =0.2,zoom_range=0.2,horizontal_flip =True)\n",
        "# traindata = traindatagenerator.flow_from_dataframe(dataframe=train,directory=dir,x_col=\"Filepath\",y_col=[\"Age\",\"Gender\",\"Racevalues\"],class_mode=\"multi_output\", batch_size=batch_size)\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9aO3SH22mFK",
        "outputId": "b0e225fb-8504-4a03-e657-1a131190336e"
      },
      "source": [
        "# # Create train and test splits of the dataset.\n",
        "# num_examples_in_test_ds = int( dataset.cardinality().numpy() * TRAIN_TEST_SPLIT )\n",
        "\n",
        "# test_ds = dataset.take( num_examples_in_test_ds )\n",
        "# train_ds = dataset.skip( num_examples_in_test_ds )\n",
        "\n",
        "# print( 'Num examples in train ds {}'.format( train_ds.cardinality() ) )\n",
        "# print( 'Num examples in test ds {}'.format( test_ds.cardinality() ) )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples in train ds 14000\n",
            "Num examples in test ds 6000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZnNB0Nm3g_"
      },
      "source": [
        "\n",
        "## 3) Model\n",
        "\n",
        "Our aim is to develop a model which has lesser parameters ( which implies lesser inference time and size ) but powerful enough so that it can generalize better.\n",
        "\n",
        "* The model takes in a batch of shape `[ None , 128 , 128 , 3 ]` and performs a number of convolutions on it as determined by `num_blocks`.\n",
        "* Each block consists of a sequence of layers : `Conv2D -> BatchNorm -> LeakyReLU`\n",
        "\n",
        "\n",
        "\n",
        "* If `lite_model` is set to `True`, we use [Separable Convolutions](https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728) which have lesser parameters. We could achieve a *faster* model, compromising its performance.\n",
        "\n",
        "* We stack such`num_blocks` blocks sequentially, where the no. of filters for each layer is taken from `num_filters`.\n",
        "\n",
        "* Next we add a number of `Dense` layers to learn the features extracted by convolutional layers. Note, we also add a `Dropout` layer, to reduce overfitting. The `rate` for each `Dropout` layer is decreased subsequently for each layer, so that the learnability of `Dense` layer with lesser units ( neurons ) is not affected.\n",
        "\n",
        "* The last `Dense` layer applies the softmax activation function which yields a probability distribution for the two classes `male` and `female`.\n",
        "\n",
        "> See [this](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/) blog for choosing the weight decay values used in the above two blocks.\n",
        "\n",
        "* 👉🏻 The output of the model is a tensor with shape `[ None, 2 ]`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnInaL-zjNCE"
      },
      "source": [
        "# Custom preprocessing layer to modify image brightness randomly.\n",
        "class RandomBrightness( tf.keras.layers.Layer ):\n",
        "\n",
        "    def __init__( self , max_delta ):\n",
        "        super( RandomBrightness , self ).__init__()\n",
        "        self.__max_delta = max_delta\n",
        "\n",
        "    def call( self , inputs ):\n",
        "        return tf.image.random_brightness( inputs , self.__max_delta )\n",
        "\n",
        "    def get_config( self ):\n",
        "        return { \"max_delta\" : self.__max_delta }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qmw6DHVG2QD"
      },
      "source": [
        "MODEL_INPUT_IMAGE_SIZE = [128, 128]\n",
        "# Negative slope coefficient for LeakyReLU.\n",
        "leaky_relu_alpha = 0.2\n",
        "\n",
        "lite_model = True\n",
        "\n",
        "# Define the conv block.\n",
        "def conv( x , num_filters , kernel_size=( 3 , 3 ) , strides=1 ):\n",
        "    if lite_model:\n",
        "        x = tf.keras.layers.SeparableConv2D( num_filters ,\n",
        "                                            kernel_size=kernel_size ,\n",
        "                                            strides=strides, \n",
        "                                            use_bias=False ,\n",
        "                                            kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                             )( x )\n",
        "    else:\n",
        "        x = tf.keras.layers.Conv2D( num_filters ,\n",
        "                                   kernel_size=kernel_size ,\n",
        "                                   strides=strides ,\n",
        "                                   use_bias=False ,\n",
        "                                   kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                   kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                    )( x )\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\n",
        "    x = tf.keras.layers.LeakyReLU( leaky_relu_alpha )( x )\n",
        "    return x\n",
        "\n",
        "def dense( x , filters , dropout_rate ):\n",
        "    x = tf.keras.layers.Dense( filters , kernel_regularizer=tf.keras.regularizers.L2( 0.1 ) , bias_regularizer=tf.keras.regularizers.L2( 0.1 ) )( x )\n",
        "    x = tf.keras.layers.LeakyReLU( alpha=leaky_relu_alpha )( x )\n",
        "    x = tf.keras.layers.Dropout( dropout_rate )( x )\n",
        "    return x\n",
        "\n",
        "# No. of convolution layers to be added.\n",
        "num_blocks = 5\n",
        "\n",
        "# Num filters for each conv layer.\n",
        "num_filters = [ 16 , 32 , 64 , 128 , 256 , 256 ]\n",
        "\n",
        "# Kernel sizes for each conv layer.\n",
        "kernel_sizes = [ 3 , 3 , 3 , 3 , 3 , 3 ]\n",
        "\n",
        "# Init a Input Layer.\n",
        "inputs = tf.keras.layers.Input(shape=MODEL_INPUT_IMAGE_SIZE + [3])\n",
        "\n",
        "def standard_conv_layers(inputs):\n",
        "  x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = BatchNormalization(axis=-1)(x)\n",
        "  x = MaxPooling2D(pool_size=(3, 3))(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = BatchNormalization(axis=-1)(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
        "  x = Activation(\"relu\")(x)\n",
        "  x = BatchNormalization(axis=-1)(x)\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  return x\n",
        "#################### Gender Classifier ###########################\n",
        "# for i in range( num_blocks ):\n",
        "#     x = conv( x , num_filters=num_filters[ i ] , kernel_size=kernel_sizes[ i ] )\n",
        "#     x = tf.keras.layers.MaxPooling2D()( x )\n",
        "\n",
        "# Flatten the output of the last Conv layer.\n",
        "x = inputs\n",
        "x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
        "x = standard_conv_layers(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "gender = Dense(2, activation='sigmoid', name='gender_output')(x)\n",
        "# x = tf.keras.layers.Flatten()( x )\n",
        "# conv_output = x \n",
        "# Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
        "# x = dense(conv_output , 256 , 0.6 )\n",
        "# x = dense(x ,64 ,0.4 )\n",
        "# x = dense(x ,32 ,0.2 )\n",
        "# gender = tf.keras.layers.Dense(2, activation='sigmoid', name='gender')(x)\n",
        "#################### End of Gender Classifier ###########################\n",
        "\n",
        "#################### Race Classifier ###########################\n",
        "# for i in range( num_blocks ):\n",
        "#     x = conv( x , num_filters=num_filters[ i ] , kernel_size=kernel_sizes[ i ] )\n",
        "#     x = tf.keras.layers.MaxPooling2D()( x )\n",
        "\n",
        "# Flatten the output of the last Conv layer.\n",
        "# x = tf.keras.layers.Flatten()( x )\n",
        "# conv_output = x \n",
        "\n",
        "# # Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
        "# x = dense(conv_output , 256 , 0.6 )\n",
        "# x = dense(x ,64 ,0.4 )\n",
        "# x = dense(x ,32 ,0.2 )\n",
        "x = inputs\n",
        "x = standard_conv_layers(inputs)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "race = tf.keras.layers.Dense(5, activation='softmax', name='race_output')(x)\n",
        "#################### End of Race Classifier ###########################\n",
        "\n",
        "#################### Age Classifier ###########################\n",
        "# for i in range( num_blocks ):\n",
        "#     x = conv( x , num_filters=num_filters[ i ] , kernel_size=kernel_sizes[ i ] )\n",
        "#     x = tf.keras.layers.MaxPooling2D()( x )\n",
        "\n",
        "# # Flatten the output of the last Conv layer.\n",
        "# x = tf.keras.layers.Flatten()( x )\n",
        "# conv_output = x \n",
        "\n",
        "# # Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
        "# x = dense(conv_output , 256 , 0.6 )\n",
        "# x = dense(x ,64 ,0.4 )\n",
        "# x = dense(x ,32 ,0.2 )\n",
        "x = inputs\n",
        "x = standard_conv_layers(inputs)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128)(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "age = tf.keras.layers.Dense(1, activation='linear', name='age_output')(x)\n",
        "#################### End of Age Classifier ###########################\n",
        "\n",
        "# Build the Model\n",
        "model = tf.keras.models.Model(inputs , [age, race, gender])\n",
        "\n",
        "# Uncomment the below to view the summary of the model.\n",
        "# model.summary()\n",
        "# tf.keras.utils.plot_model(model) # add to_file='architecture.png' to export architecture \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yobN_O2S3en9"
      },
      "source": [
        "\n",
        "Run this cell to visualize the training of the model in TensorBoard ( in this notebook itself )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycIUYrp65w7r"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JMUGVWqgAdR"
      },
      "source": [
        "## 4) **Compiling the model ( and other callbacks )** 🧱\n",
        "\n",
        "Once we've defined the architecture for our model, we'll compile our Keras model and also initialize some useful callbacks.\n",
        "\n",
        "* As we're performing classification, we'll use the Categorical Crossentropy loss function. See [`tf.keras.losses.CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) for more details.\n",
        "\n",
        "* We'll use the Adam optimizer for training our model. See [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) for more details.\n",
        "\n",
        "* For evaluating the performance of our model, we measure the accuracy of our model. See [`tf.keras.metrics.Accuracy`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy) for more details.\n",
        "\n",
        "\n",
        "#### Callbacks:\n",
        "\n",
        "* [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the Keras model as an H5 file after every epoch.\n",
        "\n",
        "* [`tf.keras.callbacks.TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) to visualize the training with TensorBoard.\n",
        "\n",
        "* [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the training when the evaluation metric i.e the MAE stops improving on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cow71DK6kjUQ"
      },
      "source": [
        "learning_rate = 1e-4\n",
        "num_epochs = 10 \n",
        "# batch_size = 2\n",
        "\n",
        "# train_ds = train_ds.batch(batch_size).repeat(num_epochs)\n",
        "# test_ds = test_ds.batch(batch_size).repeat(num_epochs)\n",
        "\n",
        "save_dir = 'checkpoints/cp.ckpt'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( save_dir )\n",
        "logdir = os.path.join( \"logs/tb_logs\" , datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") )\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard( logdir )\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy' , patience=3 )\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=learning_rate,\n",
        "        decay=learning_rate/num_epochs\n",
        "    ),\n",
        "    loss = {\n",
        "        'age_output': 'mse',\n",
        "        'race_output': 'categorical_crossentropy',\n",
        "        'gender_output': 'binary_crossentropy'\n",
        "    },\n",
        "    metrics = {\n",
        "        'age_output': 'mae',\n",
        "        'race_output': 'accuracy',\n",
        "        'gender_output': 'accuracy'\n",
        "    }\n",
        ")\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtpRh9y0orKo"
      },
      "source": [
        "## 5) **Train and Evaluate the Model** 🏋🏻‍♂️\n",
        "\n",
        "Start the training loop with all callbacks packed in.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RddzZAhSgTQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f07c38-eea9-4b8f-e53a-42955cf3db49"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = train_gen.generate_images(is_training = True, batch_size = batch_size)\n",
        "test_data = test_gen.generate_images(is_training = True, batch_size = batch_size)\n",
        "\n",
        "model.fit( \n",
        "    train_data,\n",
        "    epochs=num_epochs,  \n",
        "    validation_data=test_data,\n",
        "    callbacks=[checkpoint_callback , tensorboard_callback , early_stopping_callback]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "    179/Unknown - 2574s 14s/step - loss: 6.9344 - age_output_loss: 3.8591 - race_output_loss: 2.2421 - gender_output_loss: 0.8333 - age_output_mae: 1.5492 - race_output_accuracy: 0.3202 - gender_output_accuracy: 0.6358"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WVYKruLozh4"
      },
      "source": [
        "Evaluate the Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZKpG-IVBr_C"
      },
      "source": [
        "\n",
        "p = model.evaluate( test_ds )\n",
        "print( 'loss is {} \\n accuracy is {} %'.format( p[0] , p[1] * 100 ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spX1Piedo0-X"
      },
      "source": [
        "\n",
        "Save the Keras model to the local disk, so that we can resume training if needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TtLuHZDFry"
      },
      "source": [
        "\n",
        "model_name = 'model_gender_augmented' #@param {type: \"string\"}\n",
        "model_name_ = model_name + '.h5'\n",
        "\n",
        "model.save( model_name_ )\n",
        "files.download( model_name_ ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTw5UugS8epl"
      },
      "source": [
        "\n",
        "## 6) **Visualize the results**\n",
        "\n",
        "We'll predict the age from some images taken from `test_ds` and plot them using `matplotlib`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH_O8ZEQ8i85"
      },
      "source": [
        "\n",
        "fig = plt.figure( figsize=( 12 , 15 ) )\n",
        "classes = [ 'Male' , 'Female' ]\n",
        "rows = 5\n",
        "columns = 2\n",
        "\n",
        "i = 1\n",
        "for image , label in test_ds.unbatch().take( 10 ):\n",
        "    image = image.numpy()\n",
        "    fig.add_subplot( rows , columns , i )\n",
        "    plt.imshow( image )\n",
        "    label_ = classes[ np.argmax( model.predict( np.expand_dims( image , 0 ) ) ) ]\n",
        "    plt.axis( 'off' )\n",
        "    plt.title( 'Predicted gender : {} , actual gender : {}'.format( label_ , classes[ np.argmax( label ) ] ) )\n",
        "    i += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOFJqsf-uK9"
      },
      "source": [
        " \n",
        "## 7) **Convert to TensorFlow Lite format** 📡\n",
        "\n",
        "Our model is to be deployed in an Android app, where we'll use [TF Lite Android](https://bintray.com/google/tensorflow/tensorflow-lite) package to parse the model and make predictions.\n",
        "\n",
        "We use the `TFLiteConverter` API to convert our Keras Model ( `.h5` ) to a TF Lite buffer ( `.tflite` ). See the [official docs](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter/). We'll produce two TF Lite buffers, one with float16 quantization and other non-quantized model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwmMTQxyhToJ"
      },
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n",
        "converter.target_spec.supported_types = [ tf.float16 ]\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_q.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "files.download( '{}_q.tflite'.format( model_name ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5VTeSnGAhm_"
      },
      "source": [
        "\n",
        "For conversion to a non-quantized TF Lite buffer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jnurapqK6fw"
      },
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_nonq.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "files.download( '{}_nonq.tflite'.format( model_name ) )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uQcN2eMkrR5"
      },
      "source": [
        "\n",
        "## Utility Methods\n",
        "\n",
        "Use these methods to automate some of the tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TGGdHh5oEtK1"
      },
      "source": [
        "\n",
        "#@title Utility to zip and download a directory\n",
        "#@markdown Use this method to zip and download a directory. For ex. a TB logs \n",
        "#@markdown directory or a checkpoint(s) directory.\n",
        "\n",
        "dir_to_zip = 'tb_logs' #@param {type: \"string\"}\n",
        "output_filename = 'logs.zip' #@param {type: \"string\"}\n",
        "delete_dir_after_download = \"No\"  #@param ['Yes', 'No']\n",
        "\n",
        "os.system( \"zip -r {} {}\".format( output_filename , dir_to_zip ) )\n",
        "\n",
        "if delete_dir_after_download == \"Yes\":\n",
        "    os.system( \"rm -r {}\".format( dir_to_zip ) )\n",
        "\n",
        "files.download( output_filename )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jGbWLjNXJMSt"
      },
      "source": [
        "\n",
        "#@title Utility to delete a directory\n",
        "#@markdown Use this method to delete a directory. \n",
        "\n",
        "dir_path = ''  #@param {type: \"string\"}\n",
        "os.system( f'rm -r {dir_path}')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}