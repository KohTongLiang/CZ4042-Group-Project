{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gP9hS6C6ova"
      },
      "source": [
        "# We explore this notebook and see how we can make modification to complete our tasks\n",
        "\n",
        "Some ideas\n",
        "\n",
        "\n",
        "*   Cross-gender identification\n",
        "* Age identification\n",
        "*   Deployment to mobile devices\n",
        "\n",
        "Dataset provided in assignment brief: https://susanqq.github.io/UTKFace/\n",
        "\n",
        "Download this: https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE?resourcekey=0-01Pth1hq20K4kuGVkp3oBw\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3yl99hOe_F3"
      },
      "source": [
        "# **Age and Gender Estimation in TensorFlow ( Workbook 2, Gender Classification )**\n",
        "\n",
        "* For Age Estimation, go to [Workbook 1 ( Age Estimation )](https://colab.research.google.com/drive/1to2iolQGIVZgXFWRmRKZGrny5kfXk40h?usp=sharing)\n",
        "\n",
        "In this notebook, we train a Keras model to classify the gender of a person, given a *face-cropped* image. We use the famous [UTKFace Dataset](https://susanqq.github.io/UTKFace/), which contains 23K images where each image is labelled with its gender, age and ethinicity.\n",
        "\n",
        "\n",
        "> **Note: Please make sure that you are connected to the GPU runtime of Google Colab. Else, the training might take a decade long. Go to Runtime > Change runtime type > Hardware accelerator.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMlbjEzffKQP"
      },
      "source": [
        "## 1) **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Eb_CNn_ui6QT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgOhn0cfrkg"
      },
      "source": [
        "## 2) **Processing the data**\n",
        "\n",
        "Once we've downloaded the dataset, we need to perform the following operations on the dataset, so that it can be used for training our model,\n",
        "\n",
        "* Reading the image files as 3D NumPy arrays. Note, we'll use 3-channeled RGB images for training the model, so each array will have a shape of `[ img_width , img_height , 3 ]`.\n",
        "\n",
        "* Split the filename so as to parse the gender of the person in corresponding image. We use the `tf.strings.split()` method for performing this task.\n",
        "\n",
        "* We one-hot encode the gender, as we'll perform *a two-class* classification.\n",
        "\n",
        "Once this operations have been performed, we are left with $N$ samples where each sample consists of image array `[ 128 , 128 , 3 ]` and its corresponding label ( one-hot encoded ), the gender of that person, which has a shape `[ 1 , 2 ]`\n",
        "\n",
        "We'll use `tf.data.Dataset` as it helps us to process the data faster, taking advantage of parallel computing. The above two operations will be mapped on each filename using `tf.data.Dataset.map` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "m67XqZMHirhz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"add:0\", shape=(2,), dtype=float32)\n",
            "<TakeDataset shapes: ((128, 128, 3), ()), types: (tf.float32, tf.int32)>\n"
          ]
        }
      ],
      "source": [
        "# Image size for our model.\n",
        "MODEL_INPUT_IMAGE_SIZE = [ 128 , 128 ]\n",
        "\n",
        "TRAIN_TEST_SPLIT = 0.3\n",
        "\n",
        "# Number of samples to take from dataset\n",
        "NUM_SAMPLES = 20000\n",
        "\n",
        "# Trick to one-hot encode the label.\n",
        "y1 = tf.constant( [ 1. , 0. ] , dtype='float32' ) \n",
        "y2 = tf.constant( [ 0. , 1. ] , dtype='float32' ) \n",
        "\n",
        "# This method will be mapped for each filename in `list_ds`. \n",
        "def parse_image(filename):\n",
        "\n",
        "    # Read the image from the filename and resize it.\n",
        "    image_raw = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(image_raw ,channels=3) \n",
        "    image = tf.image.resize(image ,MODEL_INPUT_IMAGE_SIZE) / 255\n",
        "\n",
        "    # Split the filename to get the age and the gender. Convert the age ( str ) and the gender ( str ) to dtype float32.\n",
        "    parts = tf.strings.split( tf.strings.split( filename , '/' )[ 2 ] , '_' )\n",
        "\n",
        "    # One-hot encode the label\n",
        "    gender = tf.strings.to_number(parts[1])\n",
        "    gender = ( gender * y2 ) + ( ( 1 - gender ) * y1 )\n",
        "    print(gender)\n",
        "\n",
        "    return image, 2\n",
        "\n",
        "# List all the image files in the given directory.\n",
        "list_ds = tf.data.Dataset.list_files( './UTKDataset/UTKFace/*' , shuffle=True )\n",
        "# Map `parse_image` method to all filenames.\n",
        "dataset = list_ds.map( parse_image , num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
        "# dataset = list_ds.map(lambda x: tf.py_function(func=parse_image, inp=[x], Tout=(tf.float32, tf.float32)),num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
        "dataset = dataset.take( NUM_SAMPLES )\n",
        "print(dataset)\n",
        "\n",
        "# for e in dataset:\n",
        "#     print(e)\n",
        "\n",
        "# Fraction of the dataset to be used for testing.\n",
        "# split = 0.3\n",
        "\n",
        "# batch_size = 128\n",
        "\n",
        "# dir = './UTKDataset/UTKFace/'\n",
        "# image_data = []\n",
        "\n",
        "# for i in os.listdir(dir):\n",
        "#     file = i.split('_')\n",
        "#     if ((file[0].isnumeric()) and (file[1].isnumeric()) and (file[2].isnumeric())):\n",
        "#         image_data.append([file[1],i])\n",
        "\n",
        "# data = pd.DataFrame(image_data, columns=[\"Gender\",\"Filepath\"])\n",
        "\n",
        "# # data['Age'] = data.Age.astype('float')\n",
        "# data['Gender'] = data.Gender.astype('float')\n",
        "# # data['Racevalues'] = data['Racevalues'].astype('float')\n",
        "# data['Filepath'] = data.Filepath.astype('string')\n",
        "\n",
        "# # 1-hot embedding\n",
        "# # data['Age'] = tf.keras.utils.to_categorical(data['Age'])\n",
        "# data['Gender'] = tf.keras.utils.to_categorical(data['Gender'])\n",
        "# # data['Racevalues'] = tf.keras.utils.to_categorical(data['Racevalues'])\n",
        "\n",
        "# # train test split\n",
        "# train, test = train_test_split(data, test_size = split)\n",
        "# train.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7112 validated image filenames.\n",
            "Found 16593 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# testdatagenerator = ImageDataGenerator(rescale=1. /255)\n",
        "# testdata = testdatagenerator.flow_from_dataframe(dataframe=test,directory=dir,x_col=\"Filepath\",y_col=[\"Age\",\"Gender\",\"Racevalues\"],class_mode=\"multi_output\", batch_size=batch_size)\n",
        "\n",
        "# traindatagenerator = ImageDataGenerator(rescale=1. /255,shear_range =0.2,zoom_range=0.2,horizontal_flip =True)\n",
        "# traindata = traindatagenerator.flow_from_dataframe(dataframe=train,directory=dir,x_col=\"Filepath\",y_col=[\"Age\",\"Gender\",\"Racevalues\"],class_mode=\"multi_output\", batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "E9aO3SH22mFK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples in train ds 14000\n",
            "Num examples in test ds 6000\n"
          ]
        }
      ],
      "source": [
        "# Create train and test splits of the dataset.\n",
        "num_examples_in_test_ds = int( dataset.cardinality().numpy() * TRAIN_TEST_SPLIT )\n",
        "\n",
        "test_ds = dataset.take( num_examples_in_test_ds )\n",
        "train_ds = dataset.skip( num_examples_in_test_ds )\n",
        "\n",
        "print( 'Num examples in train ds {}'.format( train_ds.cardinality() ) )\n",
        "print( 'Num examples in test ds {}'.format( test_ds.cardinality() ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZnNB0Nm3g_"
      },
      "source": [
        "\n",
        "## 3) Model\n",
        "\n",
        "Our aim is to develop a model which has lesser parameters ( which implies lesser inference time and size ) but powerful enough so that it can generalize better.\n",
        "\n",
        "* The model takes in a batch of shape `[ None , 128 , 128 , 3 ]` and performs a number of convolutions on it as determined by `num_blocks`.\n",
        "* Each block consists of a sequence of layers : `Conv2D -> BatchNorm -> LeakyReLU`\n",
        "\n",
        "```\n",
        "# Define the conv block.\n",
        "if lite_model:\n",
        "        x = tf.keras.layers.SeparableConv2D( num_filters ,\n",
        "                                            kernel_size=kernel_size ,\n",
        "                                            strides=strides \n",
        "                                            , use_bias=False ,\n",
        "                                            kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                             )( x )\n",
        "    else:\n",
        "        x = tf.keras.layers.Conv2D( num_filters ,\n",
        "                                   kernel_size=kernel_size ,\n",
        "                                   strides=strides ,\n",
        "                                   use_bias=False ,\n",
        "                                   kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                   kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                    )( x )\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\n",
        "    x = tf.keras.layers.LeakyReLU( leaky_relu_alpha )( x )\n",
        "```\n",
        "\n",
        "* If `lite_model` is set to `True`, we use [Separable Convolutions](https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728) which have lesser parameters. We could achieve a *faster* model, compromising its performance.\n",
        "\n",
        "* We stack such`num_blocks` blocks sequentially, where the no. of filters for each layer is taken from `num_filters`.\n",
        "\n",
        "* Next we add a number of `Dense` layers to learn the features extracted by convolutional layers. Note, we also add a `Dropout` layer, to reduce overfitting. The `rate` for each `Dropout` layer is decreased subsequently for each layer, so that the learnability of `Dense` layer with lesser units ( neurons ) is not affected.\n",
        "\n",
        "```\n",
        "def dense( x , filters , dropout_rate ):\n",
        "    x = tf.keras.layers.Dense( filters , kernel_regularizer=tf.keras.regularizers.L2( 0.1 ) , bias_regularizer=tf.keras.regularizers.L2( 0.1 ) )( x )\n",
        "    x = tf.keras.layers.LeakyReLU( alpha=leaky_relu_alpha )( x )\n",
        "    x = tf.keras.layers.Dropout( dropout_rate )( x )\n",
        "    return x\n",
        "```\n",
        "\n",
        "* The last `Dense` layer applies the softmax activation function which yields a probability distribution for the two classes `male` and `female`.\n",
        "\n",
        "> See [this](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/) blog for choosing the weight decay values used in the above two blocks.\n",
        "\n",
        "* 👉🏻 The output of the model is a tensor with shape `[ None, 2 ]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HnInaL-zjNCE"
      },
      "outputs": [],
      "source": [
        "# Custom preprocessing layer to modify image brightness randomly.\n",
        "class RandomBrightness( tf.keras.layers.Layer ):\n",
        "\n",
        "    def __init__( self , max_delta ):\n",
        "        super( RandomBrightness , self ).__init__()\n",
        "        self.__max_delta = max_delta\n",
        "\n",
        "    def call( self , inputs ):\n",
        "        return tf.image.random_brightness( inputs , self.__max_delta )\n",
        "\n",
        "    def get_config( self ):\n",
        "        return { \"max_delta\" : self.__max_delta }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_qmw6DHVG2QD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_5 (Separabl (None, 126, 126, 16)      75        \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 126, 126, 16)      64        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 126, 126, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 63, 63, 16)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_6 (Separabl (None, 61, 61, 32)        656       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 61, 61, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 61, 61, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_7 (Separabl (None, 28, 28, 64)        2336      \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 28, 28, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_8 (Separabl (None, 12, 12, 128)       8768      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "separable_conv2d_9 (Separabl (None, 4, 4, 256)         33920     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "gender (Dense)               (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 328,733\n",
            "Trainable params: 327,741\n",
            "Non-trainable params: 992\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "MODEL_INPUT_IMAGE_SIZE = [128, 128]\n",
        "# Negative slope coefficient for LeakyReLU.\n",
        "leaky_relu_alpha = 0.2\n",
        "\n",
        "lite_model = True\n",
        "\n",
        "# Define the conv block.\n",
        "def conv( x , num_filters , kernel_size=( 3 , 3 ) , strides=1 ):\n",
        "    if lite_model:\n",
        "        x = tf.keras.layers.SeparableConv2D( num_filters ,\n",
        "                                            kernel_size=kernel_size ,\n",
        "                                            strides=strides, \n",
        "                                            use_bias=False ,\n",
        "                                            kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                             )( x )\n",
        "    else:\n",
        "        x = tf.keras.layers.Conv2D( num_filters ,\n",
        "                                   kernel_size=kernel_size ,\n",
        "                                   strides=strides ,\n",
        "                                   use_bias=False ,\n",
        "                                   kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                   kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                    )( x )\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\n",
        "    x = tf.keras.layers.LeakyReLU( leaky_relu_alpha )( x )\n",
        "    return x\n",
        "\n",
        "def dense( x , filters , dropout_rate ):\n",
        "    x = tf.keras.layers.Dense( filters , kernel_regularizer=tf.keras.regularizers.L2( 0.1 ) , bias_regularizer=tf.keras.regularizers.L2( 0.1 ) )( x )\n",
        "    x = tf.keras.layers.LeakyReLU( alpha=leaky_relu_alpha )( x )\n",
        "    x = tf.keras.layers.Dropout( dropout_rate )( x )\n",
        "    return x\n",
        "\n",
        "\n",
        "# No. of convolution layers to be added.\n",
        "num_blocks = 5\n",
        "# Num filters for each conv layer.\n",
        "num_filters = [ 16 , 32 , 64 , 128 , 256 , 256 ]\n",
        "# Kernel sizes for each conv layer.\n",
        "kernel_sizes = [ 3 , 3 , 3 , 3 , 3 , 3 ]\n",
        "\n",
        "# Init a Input Layer.\n",
        "inputs = tf.keras.layers.Input( shape=MODEL_INPUT_IMAGE_SIZE + [ 3 ] )\n",
        "\n",
        "# Add conv blocks sequentially\n",
        "x = inputs\n",
        "for i in range( num_blocks ):\n",
        "    x = conv( x , num_filters=num_filters[ i ] , kernel_size=kernel_sizes[ i ] )\n",
        "    x = tf.keras.layers.MaxPooling2D()( x )\n",
        "\n",
        "# Flatten the output of the last Conv layer.\n",
        "x = tf.keras.layers.Flatten()( x )\n",
        "conv_output = x \n",
        "\n",
        "# Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
        "x = dense( conv_output , 256 , 0.6 )\n",
        "x = dense( x , 64 , 0.4 )\n",
        "x = dense( x , 32 , 0.2 )\n",
        "\n",
        "# age = tf.keras.layers.Dense(2, activation='softmax', name='age')(x)\n",
        "gender = tf.keras.layers.Dense(2, activation='sigmoid', name='gender')(x)\n",
        "# race = tf.keras.layers.Dense(2, activation='softmax', name='race')(x)\n",
        "\n",
        "# Build the Model\n",
        "model = tf.keras.models.Model(inputs , gender)\n",
        "\n",
        "# Uncomment the below to view the summary of the model.\n",
        "model.summary()\n",
        "# tf.keras.utils.plot_model( model , to_file='architecture.png' )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yobN_O2S3en9"
      },
      "source": [
        "\n",
        "Run this cell to visualize the training of the model in TensorBoard ( in this notebook itself )."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ycIUYrp65w7r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 22272), started 12:35:25 ago. (Use '!kill 22272' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-8a8997bda56a5067\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-8a8997bda56a5067\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JMUGVWqgAdR"
      },
      "source": [
        "## 4) **Compiling the model ( and other callbacks )** 🧱\n",
        "\n",
        "Once we've defined the architecture for our model, we'll compile our Keras model and also initialize some useful callbacks.\n",
        "\n",
        "* As we're performing classification, we'll use the Categorical Crossentropy loss function. See [`tf.keras.losses.CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) for more details.\n",
        "\n",
        "* We'll use the Adam optimizer for training our model. See [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) for more details.\n",
        "\n",
        "* For evaluating the performance of our model, we measure the accuracy of our model. See [`tf.keras.metrics.Accuracy`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy) for more details.\n",
        "\n",
        "\n",
        "#### Callbacks:\n",
        "\n",
        "* [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the Keras model as an H5 file after every epoch.\n",
        "\n",
        "* [`tf.keras.callbacks.TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) to visualize the training with TensorBoard.\n",
        "\n",
        "* [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the training when the evaluation metric i.e the MAE stops improving on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "cow71DK6kjUQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<RepeatDataset shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int32)>\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.0001\n",
        "num_epochs = 10 \n",
        "batch_size = 2\n",
        "\n",
        "train_ds = train_ds.batch(batch_size).repeat(num_epochs)\n",
        "test_ds = test_ds.batch(batch_size).repeat(num_epochs)\n",
        "\n",
        "save_dir = 'checkpoints/cp.ckpt'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( save_dir )\n",
        "\n",
        "logdir = os.path.join( \"logs/tb_logs\" , datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") )\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard( logdir )\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy' , patience=3 )\n",
        "\n",
        "model.compile( \n",
        "    # loss=tf.keras.losses.sparse_categorical_crossentropy ,\n",
        "    loss=tf.keras.losses.binary_crossentropy,\n",
        "    # loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    optimizer = tf.keras.optimizers.Adam( learning_rate ) ,\n",
        "    metrics =[ 'accuracy' ]\n",
        ")\n",
        "\n",
        "\n",
        "print(train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtpRh9y0orKo"
      },
      "source": [
        "## 5) **Train and Evaluate the Model** 🏋🏻‍♂️\n",
        "\n",
        "Start the training loop with all callbacks packed in.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RddzZAhSgTQ5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:245 sigmoid_cross_entropy_with_logits_v2\n        return sigmoid_cross_entropy_with_logits(\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:132 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 2) vs (None, 1))\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36824/993041358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit( \n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\keras\\backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:245 sigmoid_cross_entropy_with_logits_v2\n        return sigmoid_cross_entropy_with_logits(\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\anaconda3\\envs\\MDP\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:132 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 2) vs (None, 1))\n"
          ]
        }
      ],
      "source": [
        "model.fit( \n",
        "    train_ds,\n",
        "    epochs=num_epochs,  \n",
        "    validation_data=test_ds,\n",
        "    callbacks=[checkpoint_callback , tensorboard_callback , early_stopping_callback]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WVYKruLozh4"
      },
      "source": [
        "Evaluate the Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZKpG-IVBr_C"
      },
      "outputs": [],
      "source": [
        "\n",
        "p = model.evaluate( test_ds )\n",
        "print( 'loss is {} \\n accuracy is {} %'.format( p[0] , p[1] * 100 ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spX1Piedo0-X"
      },
      "source": [
        "\n",
        "Save the Keras model to the local disk, so that we can resume training if needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5TtLuHZDFry"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = 'model_gender_augmented' #@param {type: \"string\"}\n",
        "model_name_ = model_name + '.h5'\n",
        "\n",
        "model.save( model_name_ )\n",
        "files.download( model_name_ ) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTw5UugS8epl"
      },
      "source": [
        "\n",
        "## 6) **Visualize the results**\n",
        "\n",
        "We'll predict the age from some images taken from `test_ds` and plot them using `matplotlib`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH_O8ZEQ8i85"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = plt.figure( figsize=( 12 , 15 ) )\n",
        "classes = [ 'Male' , 'Female' ]\n",
        "rows = 5\n",
        "columns = 2\n",
        "\n",
        "i = 1\n",
        "for image , label in test_ds.unbatch().take( 10 ):\n",
        "    image = image.numpy()\n",
        "    fig.add_subplot( rows , columns , i )\n",
        "    plt.imshow( image )\n",
        "    label_ = classes[ np.argmax( model.predict( np.expand_dims( image , 0 ) ) ) ]\n",
        "    plt.axis( 'off' )\n",
        "    plt.title( 'Predicted gender : {} , actual gender : {}'.format( label_ , classes[ np.argmax( label ) ] ) )\n",
        "    i += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOFJqsf-uK9"
      },
      "source": [
        " \n",
        "## 7) **Convert to TensorFlow Lite format** 📡\n",
        "\n",
        "Our model is to be deployed in an Android app, where we'll use [TF Lite Android](https://bintray.com/google/tensorflow/tensorflow-lite) package to parse the model and make predictions.\n",
        "\n",
        "We use the `TFLiteConverter` API to convert our Keras Model ( `.h5` ) to a TF Lite buffer ( `.tflite` ). See the [official docs](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter/). We'll produce two TF Lite buffers, one with float16 quantization and other non-quantized model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwmMTQxyhToJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n",
        "converter.target_spec.supported_types = [ tf.float16 ]\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_q.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "files.download( '{}_q.tflite'.format( model_name ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5VTeSnGAhm_"
      },
      "source": [
        "\n",
        "For conversion to a non-quantized TF Lite buffer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jnurapqK6fw"
      },
      "outputs": [],
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_nonq.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "files.download( '{}_nonq.tflite'.format( model_name ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uQcN2eMkrR5"
      },
      "source": [
        "\n",
        "## Utility Methods\n",
        "\n",
        "Use these methods to automate some of the tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TGGdHh5oEtK1"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Utility to zip and download a directory\n",
        "#@markdown Use this method to zip and download a directory. For ex. a TB logs \n",
        "#@markdown directory or a checkpoint(s) directory.\n",
        "\n",
        "dir_to_zip = 'tb_logs' #@param {type: \"string\"}\n",
        "output_filename = 'logs.zip' #@param {type: \"string\"}\n",
        "delete_dir_after_download = \"No\"  #@param ['Yes', 'No']\n",
        "\n",
        "os.system( \"zip -r {} {}\".format( output_filename , dir_to_zip ) )\n",
        "\n",
        "if delete_dir_after_download == \"Yes\":\n",
        "    os.system( \"rm -r {}\".format( dir_to_zip ) )\n",
        "\n",
        "files.download( output_filename )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jGbWLjNXJMSt"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Utility to delete a directory\n",
        "#@markdown Use this method to delete a directory. \n",
        "\n",
        "dir_path = ''  #@param {type: \"string\"}\n",
        "os.system( f'rm -r {dir_path}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "_uQcN2eMkrR5"
      ],
      "name": "CZ4042_GroupProject_Gender.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "e068d1db7b46c849f789b3c4a85e9cf2c6ba07f44bbce4a761ed871e9e6f51a1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('MDP': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
